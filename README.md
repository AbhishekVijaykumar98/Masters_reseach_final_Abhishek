# Masters_reseach_final_Abhishek

With rapid advancements in machine learning (ML) over the last few decades, it has emerged as the leading method in the industry for predictive analysis and pattern recognition. With the increasing use of ML algorithms in US courts (predictive recidivism), medical fields, childhood welfare systems, etc., data-driven algorithms now have a major impact on human safety, development, and social well-being. In academia and industry, extensive research is being conducted to ensure that these algorithms do not exhibit or amplify our social biases and provide the “fairest” output possible. In doing so, balancing fairness and accuracy is a key challenge, as achieving algorithmic fairness is often at the expense of predictive accuracy.

Prior works on algorithmic fairness have devised a commonly used pipeline for the development of fair ML models. This involves first selecting the desired notion of fairness, and then imposing this fairness criterion at one of the stages of training of the ML algorithm: on the input data (pre-processing), during the training of the algorithm (in-processing), or on the algorithm’s outputs (post-processing). This project focuses on the second step of this pipeline and is in a newer area of research which involves the confluence of feature selection and fairness-aware learning. Feature selection is an established strategy in machine learning. It is used to select a subset of features for efficient learning from large feature spaces to regulate training time and computational requirements. This project expands on this idea and introduces an idea for algorithmically fair feature selection.

Specifically, in this work, I present a new pre-processing framework called “Recursive A-Scores". This framework works by assigning a weighted score for each feature in the training dataset, based on the fairness and accuracy tradeoff that could be achieved with or without this feature. The scores are assessed recursively and used to repeatedly refine the set of features, with the goal of ultimately achieving a desired fairness notion while maintaining the best possible accuracy. I also show that this framework can be coupled with other commonly used techniques for achieving algorithmic fairness, namely Threshold Optimizer (a post-processing method) and Exponentiated Gradient (an in-processing method), to boost overall performance.

